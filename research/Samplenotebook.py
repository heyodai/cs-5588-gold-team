# This is an exmaple of what notebooks must look like when checking them into the repo, ensure that you are following this format so that your team members dont spend years understading the code

# Call in all needed imports
# import pandas as pd 
# import numpy as np 
# pip install something


# Pulling the Data in 
# use this section to pull in the data with the method that you will be using, this can be using a csv or using something like an API



# Data Exploration and understanding
# In this section take your data and start the analysis proccess for this
# This means that you can look at the data, visualzie, start pointing out trends in it, correlcation matrix 

# Data Augmentation
# This is where the data will be cleaned or changed
# We will want to be using SQL for this so we will have to ensure that we are familer with SQL or how to use pyspark 

# Modeling 
# In this section you are able to star your modeling, if you are going to be doing more then one model ensure that you are seperating the sectins out so that people are able to understand what is what

# Reporting 
# Take this section in order to report the results of your experiements
# More over after each experiement ensure that you pickle your results so that they can be used on another version of the df
